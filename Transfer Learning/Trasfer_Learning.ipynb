{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQ3B5zqbpoBi"
   },
   "source": [
    "# Retraining MobileNet SSD v2 model using tenser flow 2 and object detection API\n",
    "\n",
    "In this notebook, you will make a new neural network. Before executiong it, make sure you followed all the instructions on the `README.md` file.\n",
    "\n",
    "## *How to use:*\n",
    "\n",
    "Some cells need to be modified for your specific data base or for whatever customization you might see fit. Before executing this file, read it thoroughly and search for warnings on where to change what for a custom data base.\n",
    "\n",
    "After modifying everything that is needed, execute each cell in order. Some cells might have other instructions for you to follow outside the notebook, so be alert.\n",
    "\n",
    "All cells that require modifications will be flagged with a `# -!-` at the very beginning of it.\n",
    "\n",
    "## *Structure:*\n",
    "\n",
    "When executing the cells, two folders will be created with it. One is a folder where the images for testing the model would be downloaded into and the other one is a git repository that contains most of the external files we need. It also contains our workspace. It will be explained further in the notebook.\n",
    "\n",
    "## *Dataset:*\n",
    "\n",
    "Also important before executing this file is to have your data set made with the *PASCAL VOC* format inside the `dataset` folder.\n",
    "\n",
    "Your dataset needs also to be separated into `test` and `train` folders, like the example bellow.\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "We recommend puting only up to 20% of your dataset into the `test` folder. The rest goes into the `train`folder.\n",
    "\n",
    "### Resources Used\n",
    "- TFRecord Generator\n",
    "    - https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/_downloads/da4babe668a8afb093cc7776d7e630f3/generate_tfrecord.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUqoXeWYvOUH"
   },
   "source": [
    "# 0. Setup Paths and some configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbqFfkk_vpt7",
    "outputId": "591ce2ae-eb24-446f-ebfb-7a750433d54a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'RealTimeObjectDetection'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pfeinsper/RealTimeObjectDetection.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing this first cell, take some time to read the structure of the cloned repository.\n",
    "\n",
    "To facilitate a bit, here is a brief explanation\n",
    "\n",
    "```\n",
    "RealTimeObjectDetection/Tensorflow\n",
    "|- scripts\n",
    "|   |- *some scripts used here*\n",
    "|\n",
    "|- workspace\n",
    "    |- annotations\n",
    "    |- exported_models\n",
    "    |- images_for_testing\n",
    "    |- models \n",
    "    |- pre-trained-models\n",
    "        |- *Pre trained model we will use*\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Chance the bellow cell `DATASET_NAME` variable to match the folder of your dataset inside the `dataset` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zD-5b74ZvOUI"
   },
   "outputs": [],
   "source": [
    "# -!-\n",
    "\n",
    "DATASET_NAME = 'mc-dataset'  # change this one\n",
    "\n",
    "WORKSPACE_PATH = 'RealTimeObjectDetection/Tensorflow/workspace'\n",
    "SCRIPTS_PATH = 'RealTimeObjectDetection/Tensorflow/scripts'\n",
    "\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
    "IMAGE_PATH = 'dataset/' + DATASET_NAME\n",
    "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
    "\n",
    "PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'/pre-trained-models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsTaPzjcvOUJ"
   },
   "source": [
    "# 1. Create Label Map\n",
    "First thing to change for the custom dataset is the label map. Change the variable *labels* in the *Create label map* section to corespond your labes.\n",
    "\n",
    "Example: \n",
    "\n",
    "```python\n",
    "labels = [{'name':'object_1', 'id':1}, {'name':'object_2', 'id':2}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KTe0PgQpvOUJ"
   },
   "outputs": [],
   "source": [
    "# -!-\n",
    "\n",
    "labels = [{'name':\"McDonald's logo\", 'id':1}] # change here\n",
    "NUM_OF_CLASSES = len(labels)\n",
    "\n",
    "with open(ANNOTATION_PATH + '/label_map.pbtxt', 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\\"{}\\\"\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tc-vSFMcvOUJ"
   },
   "source": [
    "# 3. Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_c025TCvOUJ",
    "outputId": "a3170469-862c-4dc0-a1f1-3816fd83f5c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: RealTimeObjectDetection/Tensorflow/workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: RealTimeObjectDetection/Tensorflow/workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/train'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/train.record'}\n",
    "!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/test' } -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/test.record' }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agF_XA3tvOUL"
   },
   "source": [
    "# 4. Copy Model Config to Training Folder\n",
    "\n",
    "you can change the name of your new model bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GIZm9odovOUL"
   },
   "outputs": [],
   "source": [
    "# -!-\n",
    "\n",
    "CUSTOM_MODEL_NAME = 'custom_MCdonald_model' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4M4GS7w4KbMH"
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yRRwrSYrvOUL"
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$CUSTOM_MODEL_NAME\"\n",
    "\n",
    "mkdir RealTimeObjectDetection/Tensorflow/workspace/models/$1\n",
    "cp RealTimeObjectDetection/Tensorflow/workspace//pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config RealTimeObjectDetection/Tensorflow/workspace/models/$1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pmwL7cevOUM"
   },
   "source": [
    "# 5. Update Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "getXQLpnvOUM",
    "outputId": "7d657d24-47b9-4d82-daba-d2bd871cb72e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model {\n",
       "  ssd {\n",
       "    num_classes: 1\n",
       "    image_resizer {\n",
       "      fixed_shape_resizer {\n",
       "        height: 320\n",
       "        width: 320\n",
       "      }\n",
       "    }\n",
       "    feature_extractor {\n",
       "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "      depth_multiplier: 1.0\n",
       "      min_depth: 16\n",
       "      conv_hyperparams {\n",
       "        regularizer {\n",
       "          l2_regularizer {\n",
       "            weight: 3.9999998989515007e-05\n",
       "          }\n",
       "        }\n",
       "        initializer {\n",
       "          random_normal_initializer {\n",
       "            mean: 0.0\n",
       "            stddev: 0.009999999776482582\n",
       "          }\n",
       "        }\n",
       "        activation: RELU_6\n",
       "        batch_norm {\n",
       "          decay: 0.996999979019165\n",
       "          scale: true\n",
       "          epsilon: 0.0010000000474974513\n",
       "        }\n",
       "      }\n",
       "      use_depthwise: true\n",
       "      override_base_feature_extractor_hyperparams: true\n",
       "      fpn {\n",
       "        min_level: 3\n",
       "        max_level: 7\n",
       "        additional_layer_depth: 128\n",
       "      }\n",
       "    }\n",
       "    box_coder {\n",
       "      faster_rcnn_box_coder {\n",
       "        y_scale: 10.0\n",
       "        x_scale: 10.0\n",
       "        height_scale: 5.0\n",
       "        width_scale: 5.0\n",
       "      }\n",
       "    }\n",
       "    matcher {\n",
       "      argmax_matcher {\n",
       "        matched_threshold: 0.5\n",
       "        unmatched_threshold: 0.5\n",
       "        ignore_thresholds: false\n",
       "        negatives_lower_than_unmatched: true\n",
       "        force_match_for_each_row: true\n",
       "        use_matmul_gather: true\n",
       "      }\n",
       "    }\n",
       "    similarity_calculator {\n",
       "      iou_similarity {\n",
       "      }\n",
       "    }\n",
       "    box_predictor {\n",
       "      weight_shared_convolutional_box_predictor {\n",
       "        conv_hyperparams {\n",
       "          regularizer {\n",
       "            l2_regularizer {\n",
       "              weight: 3.9999998989515007e-05\n",
       "            }\n",
       "          }\n",
       "          initializer {\n",
       "            random_normal_initializer {\n",
       "              mean: 0.0\n",
       "              stddev: 0.009999999776482582\n",
       "            }\n",
       "          }\n",
       "          activation: RELU_6\n",
       "          batch_norm {\n",
       "            decay: 0.996999979019165\n",
       "            scale: true\n",
       "            epsilon: 0.0010000000474974513\n",
       "          }\n",
       "        }\n",
       "        depth: 128\n",
       "        num_layers_before_predictor: 4\n",
       "        kernel_size: 3\n",
       "        class_prediction_bias_init: -4.599999904632568\n",
       "        share_prediction_tower: true\n",
       "        use_depthwise: true\n",
       "      }\n",
       "    }\n",
       "    anchor_generator {\n",
       "      multiscale_anchor_generator {\n",
       "        min_level: 3\n",
       "        max_level: 7\n",
       "        anchor_scale: 4.0\n",
       "        aspect_ratios: 1.0\n",
       "        aspect_ratios: 2.0\n",
       "        aspect_ratios: 0.5\n",
       "        scales_per_octave: 2\n",
       "      }\n",
       "    }\n",
       "    post_processing {\n",
       "      batch_non_max_suppression {\n",
       "        score_threshold: 9.99999993922529e-09\n",
       "        iou_threshold: 0.6000000238418579\n",
       "        max_detections_per_class: 100\n",
       "        max_total_detections: 100\n",
       "        use_static_shapes: false\n",
       "      }\n",
       "      score_converter: SIGMOID\n",
       "    }\n",
       "    normalize_loss_by_num_matches: true\n",
       "    loss {\n",
       "      localization_loss {\n",
       "        weighted_smooth_l1 {\n",
       "        }\n",
       "      }\n",
       "      classification_loss {\n",
       "        weighted_sigmoid_focal {\n",
       "          gamma: 2.0\n",
       "          alpha: 0.25\n",
       "        }\n",
       "      }\n",
       "      classification_weight: 1.0\n",
       "      localization_weight: 1.0\n",
       "    }\n",
       "    encode_background_as_zeros: true\n",
       "    normalize_loc_loss_by_codesize: true\n",
       "    inplace_batchnorm_update: true\n",
       "    freeze_batchnorm: false\n",
       "  }\n",
       "}\n",
       "train_config {\n",
       "  batch_size: 4\n",
       "  data_augmentation_options {\n",
       "    random_horizontal_flip {\n",
       "    }\n",
       "  }\n",
       "  data_augmentation_options {\n",
       "    random_crop_image {\n",
       "      min_object_covered: 0.0\n",
       "      min_aspect_ratio: 0.75\n",
       "      max_aspect_ratio: 3.0\n",
       "      min_area: 0.75\n",
       "      max_area: 1.0\n",
       "      overlap_thresh: 0.0\n",
       "    }\n",
       "  }\n",
       "  sync_replicas: true\n",
       "  optimizer {\n",
       "    momentum_optimizer {\n",
       "      learning_rate {\n",
       "        cosine_decay_learning_rate {\n",
       "          learning_rate_base: 0.07999999821186066\n",
       "          total_steps: 50000\n",
       "          warmup_learning_rate: 0.026666000485420227\n",
       "          warmup_steps: 1000\n",
       "        }\n",
       "      }\n",
       "      momentum_optimizer_value: 0.8999999761581421\n",
       "    }\n",
       "    use_moving_average: false\n",
       "  }\n",
       "  fine_tune_checkpoint: \"RealTimeObjectDetection/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
       "  num_steps: 50000\n",
       "  startup_delay_steps: 0.0\n",
       "  replicas_to_aggregate: 8\n",
       "  max_number_of_boxes: 100\n",
       "  unpad_groundtruth_tensors: false\n",
       "  fine_tune_checkpoint_type: \"detection\"\n",
       "  fine_tune_checkpoint_version: V2\n",
       "}\n",
       "train_input_reader {\n",
       "  label_map_path: \"RealTimeObjectDetection/Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
       "  tf_record_input_reader {\n",
       "    input_path: \"RealTimeObjectDetection/Tensorflow/workspace/annotations/train.record\"\n",
       "  }\n",
       "}\n",
       "eval_config {\n",
       "  metrics_set: \"coco_detection_metrics\"\n",
       "  use_moving_averages: false\n",
       "}\n",
       "eval_input_reader {\n",
       "  label_map_path: \"RealTimeObjectDetection/Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
       "  shuffle: false\n",
       "  num_epochs: 1\n",
       "  tf_record_input_reader {\n",
       "    input_path: \"RealTimeObjectDetection/Tensorflow/workspace/annotations/test.record\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "\n",
    "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'\n",
    "\n",
    "\n",
    "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "\n",
    "\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  \n",
    "\n",
    "\n",
    "pipeline_config.model.ssd.num_classes = NUM_OF_CLASSES\n",
    "pipeline_config.train_config.batch_size = 4  # can be changed, but no need\n",
    "\n",
    "pipeline_config.train_config.fine_tune_checkpoint = PRETRAINED_MODEL_PATH+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "\n",
    "pipeline_config.train_input_reader.label_map_path= ANNOTATION_PATH + '/label_map.pbtxt'\n",
    "\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/train.record']\n",
    "pipeline_config.eval_input_reader[0].label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/test.record']\n",
    "\n",
    "\n",
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   \n",
    "\n",
    "\n",
    "pipeline_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ld_8gEQvOUN"
   },
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K4dKMuPExcO8"
   },
   "outputs": [],
   "source": [
    "TRAIN_STEPS = 1000  # <- you can change the number of steps to increase precision\n",
    "PRETRAINED_MODEL_DIR = '/content/RealTimeObjectDetection/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wysuZd4CvOUO",
    "outputId": "4ae8ffc5-2907-4d85-d4e4-3b832055cda5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 ../models/research/object_detection/model_main_tf2.py --model_dir=RealTimeObjectDetection/Tensorflow/workspace/models/custom_MCdonald_model --pipeline_config_path=RealTimeObjectDetection/Tensorflow/workspace/models/custom_MCdonald_model/pipeline.config --num_train_steps=1000\n"
     ]
    }
   ],
   "source": [
    "print(f'python3 ../models/research/object_detection/model_main_tf2.py --model_dir={CHECKPOINT_PATH} --pipeline_config_path={CONFIG_PATH} --num_train_steps={TRAIN_STEPS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Important*** - The above cell gives you a line of command to be executed (copied and pasted) directly into a terminal. This terminal must be inside this `Transfer Learning` directory. \n",
    "\n",
    "Once in executions, you will see some files appearing inside the `workpace/models/*your model's name*` folder. Those represent the checkpoints of the training.\n",
    "\n",
    "***Wait the execution to proceed***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7VJr_0sU8_I"
   },
   "source": [
    "# 7. Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_QEJenkyxoB"
   },
   "source": [
    "## 7.1 Download some images for testing the new model\n",
    "\n",
    "In the cell below, change the link of the image for testing in the last line for one that makes sense for testing your new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7A1PkFLIalKH",
    "outputId": "75a30f8e-efad-4c27-f73b-fd3295b4cc4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-11-24 14:34:50--  http://f.i.uol.com.br/agora/galeria/images/13285393.jpeg\n",
      "Resolving f.i.uol.com.br (f.i.uol.com.br)... 200.147.4.56, 2804:49c:3102:405:ffff:ffff:ffff:7, 2804:49c:3101:405:ffff:ffff:ffff:20, ...\n",
      "Connecting to f.i.uol.com.br (f.i.uol.com.br)|200.147.4.56|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20449 (20K) [image/jpeg]\n",
      "Saving to: ‘13285393.jpeg’\n",
      "\n",
      "     0K .......... .........                                  100% 3.07M=0.006s\n",
      "\n",
      "2021-11-24 14:34:51 (3.07 MB/s) - ‘13285393.jpeg’ saved [20449/20449]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd RealTimeObjectDetection/Tensorflow/workspace/images_for_testing\n",
    "wget http://f.i.uol.com.br/agora/galeria/images/13285393.jpeg # <-- link to img for testing - copy and paste the link for a google image here to be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24WlFqMYy72q"
   },
   "source": [
    "## 7.2 Export checkpoints and config into new model and test with downloaded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmhzqXSpbwPm",
    "outputId": "ade15c86-48c8-4c40-9386-83990b5c8fa9"
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$CUSTOM_MODEL_NAME\"\n",
    "mkdir RealTimeObjectDetection/Tensorflow/workspace/exported_models/$1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 ../models/research/object_detection/exporter_main_v2.py --input_type image_tensor --pipeline_config_path RealTimeObjectDetection/Tensorflow/workspace/models/custom_MCdonald_model/pipeline.config --trained_checkpoint_dir RealTimeObjectDetection/Tensorflow/workspace/models/custom_MCdonald_model --output_directory RealTimeObjectDetection/Tensorflow/workspace/exported_models/custom_MCdonald_model\n"
     ]
    }
   ],
   "source": [
    "print(f'python3 ../models/research/object_detection/exporter_main_v2.py --input_type image_tensor --pipeline_config_path {CONFIG_PATH} --trained_checkpoint_dir {CHECKPOINT_PATH} --output_directory RealTimeObjectDetection/Tensorflow/workspace/exported_models/{CUSTOM_MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Reminder*** - Again, this cell above gives you a command to be executed inside a terminal. Execute ir the same way you did the last one.\n",
    "\n",
    "***Wait the execution to proceed***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7pPqkZMBU_Rj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "def detect_image(IMAGE_PATHS):\n",
    "\n",
    "    \"\"\"\n",
    "    Object Detection (On Image) From TF2 Saved Model\n",
    "    =====================================\n",
    "    \"\"\"\n",
    "\n",
    "    # Enable GPU dynamic memory allocation\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    # for gpu in gpus:\n",
    "    #     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    # PROVIDE PATH TO MODEL DIRECTORY\n",
    "    PATH_TO_MODEL_DIR = f'RealTimeObjectDetection/Tensorflow/workspace/exported_models/{CUSTOM_MODEL_NAME}'\n",
    "\n",
    "    # PROVIDE PATH TO LABEL MAP\n",
    "    PATH_TO_LABELS = 'RealTimeObjectDetection/Tensorflow/workspace/annotations/label_map.pbtxt'\n",
    "\n",
    "    # PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
    "    MIN_CONF_THRESH = float(0.60)\n",
    "\n",
    "    # LOAD THE MODEL\n",
    "\n",
    "    import time\n",
    "    from object_detection.utils import label_map_util\n",
    "    from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "    PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
    "\n",
    "    print('Loading model...', end='')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
    "    detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "    # LOAD LABEL MAP DATA FOR PLOTTING\n",
    "\n",
    "    category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                      use_display_name=True)\n",
    "\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "\n",
    "    def load_image_into_numpy_array(path):\n",
    "        \"\"\"Load an image from file into a numpy array.\n",
    "        Puts image into numpy array to feed into tensorflow graph.\n",
    "        Note that by convention we put it into a numpy array with shape\n",
    "        (height, width, channels), where channels=3 for RGB.\n",
    "        Args:\n",
    "        path: the file path to the image\n",
    "        Returns:\n",
    "        uint8 numpy array with shape (img_height, img_width, 3)\n",
    "        \"\"\"\n",
    "        return np.array(Image.open(path))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
    "\n",
    "    image = cv2.imread(IMAGE_PATHS)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_expanded = np.expand_dims(image_rgb, axis=0)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    image_with_detections = image.copy()\n",
    "\n",
    "    # SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'],\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=0.5,\n",
    "        agnostic_mode=False)\n",
    "\n",
    "    print('Done')\n",
    "    # DISPLAYS OUTPUT IMAGE\n",
    "    cv2.imshow('detect', image_with_detections)\n",
    "    # CLOSES WINDOW ONCE KEY IS PRESSED\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 8.00803017616272 seconds\n",
      "Running inference for RealTimeObjectDetection/Tensorflow/workspace/images_for_testing/13285393.jpeg... Done\n"
     ]
    }
   ],
   "source": [
    "detect_image('RealTimeObjectDetection/Tensorflow/workspace/images_for_testing/13285393.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wraping up\n",
    "\n",
    "Congratulation! Now you have a working model that detects what you want.\n",
    "\n",
    "You can proceed by testing it with a webcam with the `detect_webcam_transfer.py` script. Don't forget to change the PATHs!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Trasfer_Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
